name: MLflow CI/CD Pipeline - Worker Productivity

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      max_iter:
        description: "Maximum iterations for training"
        required: false
        default: "500"
      alpha:
        description: "Alpha regularization parameter"
        required: false
        default: "0.001"
      hidden_layer_sizes:
        description: "Hidden layer sizes (comma-separated)"
        required: false
        default: "128,64,32"

env:
  PYTHON_VERSION: "3.12.7"
  MLFLOW_VERSION: "2.19.0"
  DOCKER_IMAGE_NAME: "worker-productivity-mlp"
  MODEL_NAME: "WorkerProductivityMLP"

jobs:
  # Job 1: Setup and Validation
  setup-validation:
    runs-on: ubuntu-latest
    outputs:
      should-deploy: ${{ steps.check-deploy.outputs.deploy }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check if deployment should proceed
        id: check-deploy
        run: |
          if [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "deploy=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "deploy=true" >> $GITHUB_OUTPUT
          else
            echo "deploy=false" >> $GITHUB_OUTPUT
          fi

      - name: Validate MLProject structure
        run: |
          echo "Validating MLProject structure..."
          if [ ! -f "MLProject/MLProject" ]; then
            echo "❌ MLProject file not found!"
            exit 1
          fi
          if [ ! -f "MLProject/conda.yaml" ]; then
            echo "❌ conda.yaml file not found!"
            exit 1
          fi
          if [ ! -f "MLProject/modelling.py" ]; then
            echo "❌ modelling.py file not found!"
            exit 1
          fi
          echo "✅ MLProject structure validated!"

  # Job 2: Training and Model Building
  train-model:
    runs-on: ubuntu-latest
    needs: setup-validation

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow==${{ env.MLFLOW_VERSION }}
          pip install dagshub
          if [ -f MLProject/requirements.txt ]; then
            pip install -r MLProject/requirements.txt
          else
            pip install pandas numpy scikit-learn matplotlib seaborn
          fi

      - name: Setup DagsHub Authentication
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          if [ ! -z "$DAGSHUB_TOKEN" ]; then
            dagshub auth add --token $DAGSHUB_TOKEN
            echo "✅ DagsHub authentication configured"
          else
            echo "⚠️ DagsHub token not found, using local MLflow"
          fi

      - name: Prepare training environment
        run: |
          cd MLProject
          # Set environment variables for DagsHub
          echo "DAGSHUB_REPO_OWNER=${{ secrets.DAGSHUB_REPO_OWNER || 'silmiaathqia' }}" >> $GITHUB_ENV
          echo "DAGSHUB_REPO_NAME=${{ secrets.DAGSHUB_REPO_NAME || 'Worker-Productivity-MLflow' }}" >> $GITHUB_ENV

          # Create necessary directories
          mkdir -p mlruns
          mkdir -p artifacts

          # List available data files
          echo "Available files:"
          find . -name "*.csv" -o -name "*.pkl" -o -name "*.json" | head -20

      - name: Run MLflow Project Training
        env:
          DAGSHUB_REPO_OWNER: ${{ secrets.DAGSHUB_REPO_OWNER || 'silmiaathqia' }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME || 'Worker-Productivity-MLflow' }}
        run: |
          cd MLProject

          # Set parameters from workflow inputs or defaults
          MAX_ITER=${{ github.event.inputs.max_iter || '500' }}
          ALPHA=${{ github.event.inputs.alpha || '0.001' }}
          HIDDEN_LAYERS=${{ github.event.inputs.hidden_layer_sizes || '128,64,32' }}

          echo "Training with parameters:"
          echo "- max_iter: $MAX_ITER"
          echo "- alpha: $ALPHA"
          echo "- hidden_layer_sizes: $HIDDEN_LAYERS"

          # Run MLflow project
          mlflow run . \
            --no-conda \
            -P max_iter=$MAX_ITER \
            -P alpha=$ALPHA \
            -P hidden_layer_sizes=$HIDDEN_LAYERS \
            -P learning_rate_init=0.001 \
            -P solver=adam \
            -P activation=relu

      - name: Validate Model Artifacts
        run: |
          cd MLProject
          echo "Checking for model artifacts..."

          # Check if model files exist
          if [ -f "scaler.pkl" ]; then
            echo "✅ Scaler saved successfully"
          else
            echo "❌ Scaler not found"
          fi

          if [ -f "model_info.json" ]; then
            echo "✅ Model info saved successfully"
            cat model_info.json
          else
            echo "❌ Model info not found"
          fi

          # Check MLflow artifacts
          if [ -d "mlruns" ]; then
            echo "✅ MLflow runs directory exists"
            find mlruns -name "*.pkl" -o -name "*.json" -o -name "*.png" | head -10
          else
            echo "❌ MLflow runs not found"
          fi

      - name: Upload Training Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: training-artifacts-${{ github.sha }}
          path: |
            MLProject/mlruns/
            MLProject/*.pkl
            MLProject/*.png
            MLProject/*.json
            MLProject/artifacts/
          retention-days: 30

      - name: Save Model Registry Info
        run: |
          cd MLProject
          # Create model registry summary
          cat > model_registry_info.txt << EOF
          Model Training Summary - $(date)
          =====================================
          Commit SHA: ${{ github.sha }}
          Branch: ${{ github.ref_name }}
          Workflow Run: ${{ github.run_number }}

          Parameters Used:
          - max_iter: ${{ github.event.inputs.max_iter || '500' }}
          - alpha: ${{ github.event.inputs.alpha || '0.001' }}
          - hidden_layer_sizes: ${{ github.event.inputs.hidden_layer_sizes || '128,64,32' }}

          Docker Image: silmiathqia/${{ env.DOCKER_IMAGE_NAME }}:${{ github.sha }}
          Latest Tag: silmiathqia/${{ env.DOCKER_IMAGE_NAME }}:latest

          DagsHub Repository: https://dagshub.com/${{ secrets.DAGSHUB_REPO_OWNER || 'silmiaathqia' }}/${{ secrets.DAGSHUB_REPO_NAME || 'Worker-Productivity-MLflow' }}
          EOF

          echo "Model registry info created:"
          cat model_registry_info.txt

  # Job 3: Docker Build and Push (Only for main branch or manual trigger)
  docker-build-push:
    runs-on: ubuntu-latest
    needs: [setup-validation, train-model]
    if: needs.setup-validation.outputs.should-deploy == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Download training artifacts
        uses: actions/download-artifact@v4
        with:
          name: training-artifacts-${{ github.sha }}
          path: MLProject/

      - name: Install MLflow and dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow==${{ env.MLFLOW_VERSION }}
          pip install dagshub
          pip install pandas numpy scikit-learn

      - name: Setup DagsHub for Docker Build
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          if [ ! -z "$DAGSHUB_TOKEN" ]; then
            dagshub auth add --token $DAGSHUB_TOKEN
          fi

      - name: Build Docker Image with MLflow
        env:
          DAGSHUB_REPO_OWNER: ${{ secrets.DAGSHUB_REPO_OWNER || 'silmiaathqia' }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME || 'Worker-Productivity-MLflow' }}
        run: |
          cd MLProject

          # Setup DagsHub connection for Docker build
          python -c "
          import dagshub
          import os
          dagshub.init(
              repo_owner=os.getenv('DAGSHUB_REPO_OWNER', 'silmiaathqia'),
              repo_name=os.getenv('DAGSHUB_REPO_NAME', 'Worker-Productivity-MLflow'),
              mlflow=True
          )
          "

          echo "Building Docker image from MLflow model..."

          # Try to build from registered model first, fallback to latest run
          if mlflow models build-docker \
            -m "models:/${{ env.MODEL_NAME }}/latest" \
            -n "${{ env.DOCKER_IMAGE_NAME }}" \
            --enable-mlserver; then
            echo "✅ Docker image built from registered model"
          else
            echo "⚠️ Registered model not found, trying latest run..."
            
            # Find latest run
            LATEST_RUN=$(find mlruns -name "*.pkl" -path "*/artifacts/model/*" | head -1 | sed 's|/artifacts/model/.*||' | sed 's|mlruns/[^/]*/||')
            
            if [ ! -z "$LATEST_RUN" ]; then
              mlflow models build-docker \
                -m "mlruns/0/$LATEST_RUN/artifacts/model" \
                -n "${{ env.DOCKER_IMAGE_NAME }}" \
                --enable-mlserver
              echo "✅ Docker image built from latest run"
            else
              echo "❌ Could not find model artifacts for Docker build"
              exit 1
            fi
          fi

      - name: Test Docker Image
        run: |
          echo "Testing Docker image..."
          docker images | grep ${{ env.DOCKER_IMAGE_NAME }}

          # Start container in background for testing
          docker run -d --name test-container -p 8080:8080 ${{ env.DOCKER_IMAGE_NAME }}:latest

          # Wait for container to start
          sleep 30

          # Test health endpoint
          if curl -f http://localhost:8080/health; then
            echo "✅ Docker container health check passed"
          else
            echo "⚠️ Health check failed, but container is running"
          fi

          # Stop test container
          docker stop test-container
          docker rm test-container

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Tag and Push Docker Images
        run: |
          # Tag with commit SHA and latest
          docker tag ${{ env.DOCKER_IMAGE_NAME }}:latest ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:${{ github.sha }}
          docker tag ${{ env.DOCKER_IMAGE_NAME }}:latest ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:latest

          # Push both tags
          docker push ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:${{ github.sha }}
          docker push ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:latest

          echo "✅ Docker images pushed successfully!"
          echo "🐳 Image: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:latest"
          echo "🐳 Tagged: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:${{ github.sha }}"

  # Job 4: Create Release Archive and Upload
  create-release:
    runs-on: ubuntu-latest
    needs: [train-model, docker-build-push]
    if: always() && needs.train-model.result == 'success'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download training artifacts
        uses: actions/download-artifact@v4
        with:
          name: training-artifacts-${{ github.sha }}
          path: artifacts/

      - name: Create Release Archive
        run: |
          # Create comprehensive release archive
          mkdir -p release-package

          # Copy artifacts
          cp -r artifacts/* release-package/ 2>/dev/null || true

          # Create release info
          cat > release-package/RELEASE_INFO.md << EOF
          # Worker Productivity Model Release

          **Release Date:** $(date)
          **Commit SHA:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          **Workflow Run:** ${{ github.run_number }}

          ## Model Information
          - **Model Type:** MLPClassifier (Multi-layer Perceptron)
          - **Use Case:** Worker Productivity Classification
          - **Classes:** High, Medium, Low Productivity

          ## Training Parameters
          - **Max Iterations:** ${{ github.event.inputs.max_iter || '500' }}
          - **Alpha (L2 Regularization):** ${{ github.event.inputs.alpha || '0.001' }}
          - **Hidden Layer Sizes:** ${{ github.event.inputs.hidden_layer_sizes || '128,64,32' }}

          ## Docker Deployment
          \`\`\`bash
          # Pull and run the model
          docker pull ${{ secrets.DOCKER_USERNAME }}/worker-productivity-mlp:latest
          docker run -p 8080:8080 ${{ secrets.DOCKER_USERNAME }}/worker-productivity-mlp:latest
          \`\`\`

          ## MLflow Model URI
          - **Registered Model:** models:/WorkerProductivityMLP/latest
          - **DagsHub:** https://dagshub.com/${{ secrets.DAGSHUB_REPO_OWNER || 'silmiaathqia' }}/${{ secrets.DAGSHUB_REPO_NAME || 'Worker-Productivity-MLflow' }}

          ## Files Included
          - Model artifacts (mlruns/)
          - Scaler (scaler.pkl)
          - Model metadata (model_info.json)
          - Performance visualizations (*.png)
          - Training logs
          EOF

          # Create deployment script
          cat > release-package/deploy.sh << 'EOF'
          #!/bin/bash
          echo "Deploying Worker Productivity Model..."

          # Pull latest Docker image
          docker pull silmiathqia/worker-productivity-mlp:latest

          # Stop existing container if running
          docker stop worker-productivity-model 2>/dev/null || true
          docker rm worker-productivity-model 2>/dev/null || true

          # Run new container
          docker run -d \
            --name worker-productivity-model \
            -p 8080:8080 \
            --restart unless-stopped \
            silmiathqia/worker-productivity-mlp:latest

          echo "Model deployed! Access at http://localhost:8080"
          echo "Health check: curl http://localhost:8080/health"
          EOF

          chmod +x release-package/deploy.sh

          # Create archive
          tar -czf model-release-${{ github.sha }}.tar.gz release-package/

          echo "Release archive created: model-release-${{ github.sha }}.tar.gz"
          ls -la model-release-${{ github.sha }}.tar.gz

      - name: Upload Release Archive
        uses: actions/upload-artifact@v4
        with:
          name: model-release-${{ github.sha }}
          path: |
            model-release-${{ github.sha }}.tar.gz
            release-package/
          retention-days: 90

      # Optional: Upload to Google Drive (if configured)
      - name: Upload to Google Drive (Optional)
        if: env.GOOGLE_DRIVE_FOLDER_ID != ''
        run: |
          echo "Google Drive upload would happen here"
          echo "Archive: model-release-${{ github.sha }}.tar.gz"
          # Implement Google Drive upload logic if needed

  # Job 5: Notification and Summary
  notify-completion:
    runs-on: ubuntu-latest
    needs: [setup-validation, train-model, docker-build-push, create-release]
    if: always()

    steps:
      - name: Create Status Summary
        run: |
          echo "## 🚀 MLflow CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Job Status" >> $GITHUB_STEP_SUMMARY
          echo "- Setup & Validation: ${{ needs.setup-validation.result == 'success' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Model Training: ${{ needs.train-model.result == 'success' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Docker Build: ${{ needs.docker-build-push.result == 'success' && '✅' || needs.docker-build-push.result == 'skipped' && '⏭️' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Release Creation: ${{ needs.create-release.result == 'success' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ "${{ needs.docker-build-push.result }}" == "success" ]]; then
            echo "### 🐳 Docker Image" >> $GITHUB_STEP_SUMMARY
            echo "- **Latest:** \`${{ secrets.DOCKER_USERNAME }}/worker-productivity-mlp:latest\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Tagged:** \`${{ secrets.DOCKER_USERNAME }}/worker-productivity-mlp:${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quick Deploy:**" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
            echo "docker run -p 8080:8080 ${{ secrets.DOCKER_USERNAME }}/worker-productivity-mlp:latest" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Model Tracking" >> $GITHUB_STEP_SUMMARY
          echo "- **DagsHub:** [View Experiments](https://dagshub.com/${{ secrets.DAGSHUB_REPO_OWNER || 'silmiaathqia' }}/${{ secrets.DAGSHUB_REPO_NAME || 'Worker-Productivity-MLflow' }})" >> $GITHUB_STEP_SUMMARY
          echo "- **Model Registry:** \`models:/WorkerProductivityMLP/latest\`" >> $GITHUB_STEP_SUMMARY

      - name: Check Overall Status
        run: |
          if [[ "${{ needs.train-model.result }}" == "success" ]]; then
            echo "🎉 Pipeline completed successfully!"
            echo "✅ Model trained and ready for deployment"
          else
            echo "❌ Pipeline failed during training"
            exit 1
          fi
